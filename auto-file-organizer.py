#!/usr/bin/env python3
"""
æ™ºèƒ½æ–‡ä»¶æ•´ç†å™¨ - è‡ªåŠ¨æ•´ç†æ‚ä¹±çš„æ–‡ä»¶å¤¹
"""

import os
import shutil
import datetime
import time
import argparse
import re
import hashlib
from pathlib import Path
from collections import defaultdict

# æ–‡ä»¶ç±»å‹æ˜ å°„
FILE_TYPES = {
    # å›¾åƒæ–‡ä»¶
    "å›¾ç‰‡": [".jpg", ".jpeg", ".png", ".gif", ".bmp", ".tiff", ".webp", ".svg", ".heic", ".raw", ".cr2"],
    
    # æ–‡æ¡£æ–‡ä»¶
    "æ–‡æ¡£": [".doc", ".docx", ".pdf", ".txt", ".rtf", ".odt", ".pages", ".md", ".ppt", ".pptx", ".key", ".odp", ".xls", ".xlsx", ".csv", ".numbers", ".ods"],
    
    # éŸ³é¢‘æ–‡ä»¶
    "éŸ³é¢‘": [".mp3", ".wav", ".flac", ".aac", ".ogg", ".m4a", ".wma", ".aiff"],
    
    # è§†é¢‘æ–‡ä»¶
    "è§†é¢‘": [".mp4", ".avi", ".mov", ".wmv", ".mkv", ".flv", ".webm", ".m4v", ".mpg", ".mpeg", ".3gp"],
    
    # å‹ç¼©æ–‡ä»¶
    "å‹ç¼©æ–‡ä»¶": [".zip", ".rar", ".7z", ".tar", ".gz", ".bz2", ".xz", ".iso"],
    
    # ä»£ç æ–‡ä»¶
    "ä»£ç ": [".py", ".java", ".c", ".cpp", ".h", ".js", ".html", ".css", ".php", ".rb", ".go", ".swift", ".kt", ".ts", ".json", ".xml", ".yml", ".yaml", ".sql"],
    
    # å¯æ‰§è¡Œæ–‡ä»¶
    "å¯æ‰§è¡Œæ–‡ä»¶": [".exe", ".msi", ".app", ".bat", ".sh", ".cmd", ".com", ".gadget", ".vb", ".vbs", ".ws", ".wsf"],
}

# åå‘æ˜ å°„ï¼ˆæ‰©å±•ååˆ°ç±»å‹ï¼‰
EXT_TO_TYPE = {}
for folder, extensions in FILE_TYPES.items():
    for ext in extensions:
        EXT_TO_TYPE[ext] = folder

def parse_arguments():
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æ–‡ä»¶æ•´ç†å™¨ - è‡ªåŠ¨æ•´ç†æ‚ä¹±çš„æ–‡ä»¶å¤¹")
    
    parser.add_argument("source_dir", type=str, nargs="?", default=".", 
                        help="è¦æ•´ç†çš„æºç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)")
    
    parser.add_argument("--mode", type=str, choices=["type", "date", "name", "size", "duplicate", "custom", "analyze"], 
                        default="type", help="æ•´ç†æ¨¡å¼ (é»˜è®¤: æŒ‰æ–‡ä»¶ç±»å‹)")
    
    parser.add_argument("--recursive", action="store_true", 
                        help="é€’å½’å¤„ç†å­ç›®å½•ä¸­çš„æ–‡ä»¶")
    
    parser.add_argument("--dry-run", action="store_true", 
                        help="ä»…æ˜¾ç¤ºä¼šè¿›è¡Œçš„æ“ä½œï¼Œä¸å®é™…ç§»åŠ¨æ–‡ä»¶")
    
    parser.add_argument("--date-format", type=str, default="%Y-%m", 
                        help="æ—¥æœŸæ¨¡å¼ä¸‹çš„æ–‡ä»¶å¤¹å‘½åæ ¼å¼ (é»˜è®¤: å¹´-æœˆ)")
    
    parser.add_argument("--size-bins", type=str, default="1MB,10MB,100MB,1GB", 
                        help="å¤§å°æ¨¡å¼ä¸‹çš„åˆ†ç±»åŒºé—´ï¼Œç”¨é€—å·åˆ†éš” (é»˜è®¤: 1MB,10MB,100MB,1GB)")
    
    parser.add_argument("--min-size", type=str, default="10KB", 
                        help="è¦å¤„ç†çš„æœ€å°æ–‡ä»¶å¤§å° (é»˜è®¤: 10KB)")
    
    parser.add_argument("--exclude", type=str, default="", 
                        help="è¦æ’é™¤çš„æ–‡ä»¶æˆ–ç›®å½•æ¨¡å¼ï¼Œç”¨é€—å·åˆ†éš” (ä¾‹å¦‚: .git*,node_modules)")
    
    parser.add_argument("--custom-rules", type=str, default="", 
                        help="è‡ªå®šä¹‰æ•´ç†è§„åˆ™æ–‡ä»¶çš„è·¯å¾„")
    
    parser.add_argument("--include-hidden", action="store_true", 
                        help="åŒ…æ‹¬éšè—æ–‡ä»¶ (é»˜è®¤: æ’é™¤)")
    
    parser.add_argument("--no-misc", action="store_true", 
                        help="ä¸åˆ›å»º'æ‚é¡¹'æ–‡ä»¶å¤¹ (é»˜è®¤: åˆ›å»ºä»¥å­˜å‚¨æœªåˆ†ç±»æ–‡ä»¶)")
    
    parser.add_argument("--keep-structure", action="store_true", 
                        help="åœ¨é€’å½’æ¨¡å¼ä¸‹ä¿æŒåŸå§‹ç›®å½•ç»“æ„")
    
    parser.add_argument("--organize-by", type=str, choices=["move", "copy", "link"], 
                        default="move", help="æ•´ç†æ–‡ä»¶çš„æ–¹å¼ (é»˜è®¤: ç§»åŠ¨)")
    
    return parser.parse_args()

# æ–‡ä»¶å¤§å°è½¬æ¢å‡½æ•°
def parse_size(size_str):
    """å°†äººç±»å¯è¯»çš„å¤§å°å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—èŠ‚æ•°"""
    units = {"B": 1, "KB": 1024, "MB": 1024**2, "GB": 1024**3, "TB": 1024**4}
    
    size_str = size_str.upper().replace(" ", "")
    
    if not re.match(r'^\d+(\.\d+)?[A-Z]+$', size_str):
        raise ValueError(f"æ— æ•ˆçš„å¤§å°æ ¼å¼: {size_str}")
    
    number = float(re.sub(r'[A-Z]+$', '', size_str))
    unit = re.sub(r'^\d+(\.\d+)?', '', size_str)
    
    if unit not in units:
        raise ValueError(f"æœªçŸ¥çš„å¤§å°å•ä½: {unit}")
    
    return int(number * units[unit])

def format_size(size_bytes):
    """å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºäººç±»å¯è¯»çš„æ ¼å¼"""
    if size_bytes < 1024:
        return f"{size_bytes}B"
    elif size_bytes < 1024**2:
        return f"{size_bytes/1024:.1f}KB"
    elif size_bytes < 1024**3:
        return f"{size_bytes/(1024**2):.1f}MB"
    elif size_bytes < 1024**4:
        return f"{size_bytes/(1024**3):.1f}GB"
    else:
        return f"{size_bytes/(1024**4):.1f}TB"

def should_process_file(file_path, args):
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†æ­¤æ–‡ä»¶"""
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    if os.path.getsize(file_path) < parse_size(args.min_size):
        return False
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºéšè—æ–‡ä»¶
    if not args.include_hidden and os.path.basename(file_path).startswith('.'):
        return False
    
    # æ£€æŸ¥æ’é™¤æ¨¡å¼
    if args.exclude:
        exclude_patterns = [p.strip() for p in args.exclude.split(',')]
        for pattern in exclude_patterns:
            if re.search(pattern, file_path):
                return False
    
    return True

def get_file_hash(file_path, block_size=65536):
    """è®¡ç®—æ–‡ä»¶çš„SHA-256å“ˆå¸Œå€¼"""
    sha256 = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for block in iter(lambda: f.read(block_size), b''):
            sha256.update(block)
    return sha256.hexdigest()

def organize_by_type(file_path, source_dir, args):
    """æŒ‰æ–‡ä»¶ç±»å‹æ•´ç†"""
    _, ext = os.path.splitext(file_path.lower())
    
    if ext in EXT_TO_TYPE:
        target_dir = os.path.join(source_dir, EXT_TO_TYPE[ext])
    else:
        if args.no_misc:
            return None
        target_dir = os.path.join(source_dir, "æ‚é¡¹")
    
    return target_dir

def organize_by_date(file_path, source_dir, args):
    """æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¥æœŸæ•´ç†"""
    mod_time = os.path.getmtime(file_path)
    date_str = datetime.datetime.fromtimestamp(mod_time).strftime(args.date_format)
    target_dir = os.path.join(source_dir, date_str)
    return target_dir

def organize_by_name(file_path, source_dir, args):
    """æŒ‰æ–‡ä»¶åé¦–å­—æ¯æ•´ç†"""
    filename = os.path.basename(file_path)
    
    # è·å–é¦–å­—æ¯æˆ–é¦–ä¸ªæ±‰å­—
    first_char = filename[0].upper()
    
    # è‹±æ–‡å­—æ¯å½’ç±»åˆ°ç›¸åº”å­—æ¯æ–‡ä»¶å¤¹
    if 'A' <= first_char <= 'Z':
        target_dir = os.path.join(source_dir, first_char)
    # æ•°å­—å½’ç±»åˆ°"æ•°å­—"æ–‡ä»¶å¤¹
    elif '0' <= first_char <= '9':
        target_dir = os.path.join(source_dir, "æ•°å­—")
    # æ±‰å­—å’Œå…¶ä»–å­—ç¬¦å½’ç±»åˆ°"å…¶ä»–"æ–‡ä»¶å¤¹
    else:
        target_dir = os.path.join(source_dir, "å…¶ä»–")
    
    return target_dir

def organize_by_size(file_path, source_dir, args):
    """æŒ‰æ–‡ä»¶å¤§å°æ•´ç†"""
    size = os.path.getsize(file_path)
    
    # è§£æå¤§å°åŒºé—´
    size_bins = [parse_size(bin_str.strip()) for bin_str in args.size_bins.split(',')]
    size_bins.sort()
    
    # ç¡®å®šæ–‡ä»¶æ‰€å±åŒºé—´
    for i, bin_size in enumerate(size_bins):
        if size < bin_size:
            if i == 0:
                return os.path.join(source_dir, f"å°äº{format_size(bin_size)}")
            else:
                return os.path.join(source_dir, f"{format_size(size_bins[i-1])}-{format_size(bin_size)}")
    
    # å¤§äºæœ€å¤§åŒºé—´
    return os.path.join(source_dir, f"å¤§äº{format_size(size_bins[-1])}")

def find_duplicates(file_paths):
    """æŸ¥æ‰¾é‡å¤æ–‡ä»¶"""
    # é¦–å…ˆæŒ‰å¤§å°åˆ†ç»„
    size_groups = defaultdict(list)
    for file_path in file_paths:
        size = os.path.getsize(file_path)
        size_groups[size].append(file_path)
    
    # ç„¶ååªå¯¹ç›¸åŒå¤§å°çš„æ–‡ä»¶è®¡ç®—å“ˆå¸Œå€¼
    duplicates = []
    hash_groups = defaultdict(list)
    
    # åªå¤„ç†æœ‰å¤šä¸ªæ–‡ä»¶çš„å¤§å°ç»„
    for size, files in size_groups.items():
        if len(files) < 2:
            continue
        
        for file_path in files:
            file_hash = get_file_hash(file_path)
            hash_groups[file_hash].append(file_path)
    
    # æ”¶é›†é‡å¤æ–‡ä»¶ï¼ˆæœ‰ç›¸åŒå“ˆå¸Œå€¼çš„æ–‡ä»¶ï¼‰
    for hash_val, files in hash_groups.items():
        if len(files) > 1:
            duplicates.append(files)
    
    return duplicates

def organize_by_custom(file_path, source_dir, args, rules=None):
    """ä½¿ç”¨è‡ªå®šä¹‰è§„åˆ™æ•´ç†æ–‡ä»¶"""
    if not rules:
        return None
    
    filename = os.path.basename(file_path)
    ext = os.path.splitext(filename)[1].lower()
    
    for rule_name, patterns in rules.items():
        for pattern in patterns:
            if re.search(pattern, filename, re.IGNORECASE):
                return os.path.join(source_dir, rule_name)
    
    if args.no_misc:
        return None
    return os.path.join(source_dir, "æ‚é¡¹")

def process_file(file_path, source_dir, args, rules=None):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    if not should_process_file(file_path, args):
        return None
    
    # æ ¹æ®æ‰€é€‰æ¨¡å¼ç¡®å®šç›®æ ‡ç›®å½•
    if args.mode == "type":
        target_dir = organize_by_type(file_path, source_dir, args)
    elif args.mode == "date":
        target_dir = organize_by_date(file_path, source_dir, args)
    elif args.mode == "name":
        target_dir = organize_by_name(file_path, source_dir, args)
    elif args.mode == "size":
        target_dir = organize_by_size(file_path, source_dir, args)
    elif args.mode == "custom":
        target_dir = organize_by_custom(file_path, source_dir, args, rules)
    else:
        return None
    
    if not target_dir:
        return None
    
    # åˆ›å»ºç›®æ ‡ç›®å½•ï¼ˆå¦‚æœæ˜¯dry runåˆ™ä»…æ‰“å°ï¼‰
    if not args.dry_run and not os.path.exists(target_dir):
        os.makedirs(target_dir)
    
    # ç¡®å®šç›®æ ‡æ–‡ä»¶è·¯å¾„
    filename = os.path.basename(file_path)
    target_path = os.path.join(target_dir, filename)
    
    # å¤„ç†æ–‡ä»¶åå†²çª
    counter = 1
    while os.path.exists(target_path) and not args.dry_run:
        name, ext = os.path.splitext(filename)
        target_path = os.path.join(target_dir, f"{name}_{counter}{ext}")
        counter += 1
    
    return target_path

def load_custom_rules(rules_file):
    """ä»æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰è§„åˆ™"""
    if not os.path.exists(rules_file):
        print(f"é”™è¯¯: è‡ªå®šä¹‰è§„åˆ™æ–‡ä»¶ '{rules_file}' ä¸å­˜åœ¨ã€‚")
        return None
    
    rules = {}
    current_category = None
    
    with open(rules_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
            if not line or line.startswith('#'):
                continue
            
            # ç±»åˆ«è¡Œ
            if line.startswith('[') and line.endswith(']'):
                current_category = line[1:-1].strip()
                rules[current_category] = []
            # è§„åˆ™è¡Œ
            elif current_category is not None:
                rules[current_category].append(line)
    
    return rules

def analyze_directory(directory, args):
    """åˆ†æç›®å½•å¹¶ç”ŸæˆæŠ¥å‘Š"""
    print(f"\nğŸ“Š ç›®å½•åˆ†æ: {directory}")
    print("=" * 60)
    
    all_files = []
    total_size = 0
    extension_count = defaultdict(int)
    extension_size = defaultdict(int)
    type_count = defaultdict(int)
    type_size = defaultdict(int)
    
    # éå†ç›®å½•
    for root, dirs, files in os.walk(directory):
        # æ’é™¤ä¸éœ€è¦å¤„ç†çš„ç›®å½•
        if not args.include_hidden:
            dirs[:] = [d for d in dirs if not d.startswith('.')]
        
        if args.exclude:
            exclude_patterns = [p.strip() for p in args.exclude.split(',')]
            for pattern in exclude_patterns:
                dirs[:] = [d for d in dirs if not re.search(pattern, os.path.join(root, d))]
        
        for file in files:
            file_path = os.path.join(root, file)
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†æ­¤æ–‡ä»¶
            if not should_process_file(file_path, args):
                continue
            
            all_files.append(file_path)
            
            # ç»Ÿè®¡æ–‡ä»¶å¤§å°
            size = os.path.getsize(file_path)
            total_size += size
            
            # ç»Ÿè®¡æ‰©å±•å
            _, ext = os.path.splitext(file.lower())
            extension_count[ext] += 1
            extension_size[ext] += size
            
            # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
            file_type = "æ‚é¡¹"
            if ext in EXT_TO_TYPE:
                file_type = EXT_TO_TYPE[ext]
            type_count[file_type] += 1
            type_size[file_type] += size
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡
    print(f"æ€»æ–‡ä»¶æ•°: {len(all_files)}")
    print(f"æ€»å¤§å°: {format_size(total_size)}")
    print(f"å¹³å‡æ–‡ä»¶å¤§å°: {format_size(total_size / max(1, len(all_files)))}")
    
    # æŒ‰æ–‡ä»¶ç±»å‹æ‰“å°ç»Ÿè®¡
    print("\nğŸ—‚ï¸ æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡:")
    print(f"{'ç±»å‹':<15} {'æ•°é‡':<10} {'å¤§å°':<10} {'å æ¯”':<10}")
    print("-" * 45)
    
    for file_type in sorted(type_count.keys()):
        count = type_count[file_type]
        size = type_size[file_type]
        percent = (size / total_size) * 100 if total_size > 0 else 0
        print(f"{file_type:<15} {count:<10} {format_size(size):<10} {percent:.1f}%")
    
    # æ‰“å°å‰10ä¸ªæœ€å¸¸è§çš„æ‰©å±•å
    print("\nğŸ“‘ æœ€å¸¸è§çš„æ–‡ä»¶ç±»å‹:")
    print(f"{'æ‰©å±•å':<10} {'æ•°é‡':<10} {'å¤§å°':<10} {'å æ¯”':<10}")
    print("-" * 45)
    
    for ext, count in sorted(extension_count.items(), key=lambda x: x[1], reverse=True)[:10]:
        size = extension_size[ext]
        percent = (size / total_size) * 100 if total_size > 0 else 0
        print(f"{ext or '(æ— )':<10} {count:<10} {format_size(size):<10} {percent:.1f}%")
    
    # æŸ¥æ‰¾é‡å¤æ–‡ä»¶
    print("\nğŸ” æŸ¥æ‰¾é‡å¤æ–‡ä»¶...")
    duplicates = find_duplicates(all_files)
    
    if duplicates:
        dup_count = sum(len(group) for group in duplicates)
        dup_size = sum(os.path.getsize(group[0]) * (len(group) - 1) for group in duplicates)
        print(f"æ‰¾åˆ° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶ï¼Œå…± {dup_count} ä¸ªæ–‡ä»¶")
        print(f"å¯èŠ‚çœç©ºé—´: {format_size(dup_size)}")
        
        # æ‰“å°å‰5ç»„é‡å¤æ–‡ä»¶
        print("\nç¤ºä¾‹é‡å¤æ–‡ä»¶ç»„:")
        for i, group in enumerate(duplicates[:5]):
            print(f"\nç»„ {i+1} ({len(group)} ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ª {format_size(os.path.getsize(group[0]))})")
            for j, file_path in enumerate(group[:3]):
                print(f"  {j+1}. {os.path.relpath(file_path, directory)}")
            if len(group) > 3:
                print(f"  ...ä»¥åŠå…¶ä»– {len(group) - 3} ä¸ªæ–‡ä»¶")
    else:
        print("æ²¡æœ‰æ‰¾åˆ°é‡å¤æ–‡ä»¶ã€‚")
    
    print("\nğŸ’¡ å»ºè®®:")
    
    # æ ¹æ®åˆ†æç»“æœç»™å‡ºå»ºè®®
    if duplicates:
        potential_savings = sum(os.path.getsize(group[0]) * (len(group) - 1) for group in duplicates)
        if potential_savings > total_size * 0.1:  # å¦‚æœå¯ä»¥èŠ‚çœè¶…è¿‡10%çš„ç©ºé—´
            print(f"- å¤„ç†é‡å¤æ–‡ä»¶å¯ä»¥èŠ‚çœ {format_size(potential_savings)} ({(potential_savings/total_size*100):.1f}%) çš„ç©ºé—´")
    
    # å»ºè®®æ•´ç†å¤§å‹æ–‡ä»¶ç±»å‹
    large_types = [(t, s) for t, s in type_size.items() if s > total_size * 0.2]
    if large_types:
        print(f"- è€ƒè™‘ä¼˜å…ˆæ•´ç†ä»¥ä¸‹å ç”¨ç©ºé—´è¾ƒå¤§çš„æ–‡ä»¶ç±»å‹:")
        for file_type, size in sorted(large_types, key=lambda x: x[1], reverse=True):
            print(f"  * {file_type} ({format_size(size)}, {(size/total_size*100):.1f}%)")
    
    # å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„å¤§å‹æ–‡ä»¶ç±»å‹ï¼Œå»ºè®®æŒ‰æ—¥æœŸæˆ–ç±»å‹æ•´ç†
    else:
        print("- å»ºè®®ä½¿ç”¨ '--mode type' æŒ‰æ–‡ä»¶ç±»å‹æ•´ç†æˆ– '--mode date' æŒ‰æ—¥æœŸæ•´ç†")
    
    print("=" * 60)

def organize_files(args):
    """æ•´ç†æ–‡ä»¶çš„ä¸»å‡½æ•°"""
    source_dir = os.path.abspath(args.source_dir)
    
    if not os.path.exists(source_dir):
        print(f"é”™è¯¯: æºç›®å½• '{source_dir}' ä¸å­˜åœ¨ã€‚")
        return
    
    print(f"\nğŸš€ æ™ºèƒ½æ–‡ä»¶æ•´ç†å™¨")
    print(f"æºç›®å½•: {source_dir}")
    print(f"æ¨¡å¼: {args.mode}")
    print(f"{'(ä»…æ˜¾ç¤ºæ“ä½œï¼Œä¸å®é™…ç§»åŠ¨æ–‡ä»¶)' if args.dry_run else ''}")
    print("=" * 60)
    
    # å¦‚æœæ˜¯åˆ†ææ¨¡å¼ï¼Œåªè¿›è¡Œåˆ†æä¸æ•´ç†
    if args.mode == "analyze":
        analyze_directory(source_dir, args)
        return
    
    # åŠ è½½è‡ªå®šä¹‰è§„åˆ™
    custom_rules = None
    if args.mode == "custom":
        if not args.custom_rules:
            print("é”™è¯¯: è‡ªå®šä¹‰æ¨¡å¼éœ€è¦æŒ‡å®šè§„åˆ™æ–‡ä»¶ (--custom-rules)")
            return
        custom_rules = load_custom_rules(args.custom_rules)
        if not custom_rules:
            return
    
    # æ”¶é›†è¦å¤„ç†çš„æ–‡ä»¶
    all_files = []
    
    if args.recursive:
        for root, dirs, files in os.walk(source_dir):
            # æ’é™¤ä¸éœ€è¦å¤„ç†çš„ç›®å½•
            if not args.include_hidden:
                dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            if args.exclude:
                exclude_patterns = [p.strip() for p in args.exclude.split(',')]
                for pattern in exclude_patterns:
                    dirs[:] = [d for d in dirs if not re.search(pattern, os.path.join(root, d))]
            
            for file in files:
                file_path = os.path.join(root, file)
                all_files.append(file_path)
    else:
        for file in os.listdir(source_dir):
            file_path = os.path.join(source_dir, file)
            if os.path.isfile(file_path):
                all_files.append(file_path)
    
    # é‡å¤æ–‡ä»¶å¤„ç†
    if args.mode == "duplicate":
        print("æŸ¥æ‰¾é‡å¤æ–‡ä»¶...")
        duplicates = find_duplicates(all_files)
        
        if not duplicates:
            print("æ²¡æœ‰å‘ç°é‡å¤æ–‡ä»¶ã€‚")
            return
        
        # åˆ›å»ºé‡å¤æ–‡ä»¶ç›®å½•
        duplicate_dir = os.path.join(source_dir, "é‡å¤æ–‡ä»¶")
        if not args.dry_run and not os.path.exists(duplicate_dir):
            os.makedirs(duplicate_dir)
        
        print(f"\næ‰¾åˆ° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶:")
        
        total_saved = 0
        for i, group in enumerate(duplicates):
            # ä¿ç•™ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œç§»åŠ¨å…¶ä½™æ–‡ä»¶
            original = group[0]
            duplicates_to_move = group[1:]
            
            group_dir = os.path.join(duplicate_dir, f"ç»„_{i+1}")
            if not args.dry_run and not os.path.exists(group_dir):
                os.makedirs(group_dir)
            
            print(f"\nç»„ {i+1} ({len(group)} ä¸ªæ–‡ä»¶, æ¯ä¸ª {format_size(os.path.getsize(original))})")
            print(f"  ä¿ç•™: {os.path.relpath(original, source_dir)}")
            
            for dup in duplicates_to_move:
                saved_space = os.path.getsize(dup)
                total_saved += saved_space
                
                target_path = os.path.join(group_dir, os.path.basename(dup))
                print(f"  ç§»åŠ¨: {os.path.relpath(dup, source_dir)} -> {os.path.relpath(target_path, source_dir)}")
                
                if not args.dry_run:
                    counter = 1
                    while os.path.exists(target_path):
                        name, ext = os.path.splitext(os.path.basename(dup))
                        target_path = os.path.join(group_dir, f"{name}_{counter}{ext}")
                        counter += 1
                    
                    if args.organize_by == "move":
                        shutil.move(dup, target_path)
                    elif args.organize_by == "copy":
                        shutil.copy2(dup, target_path)
                    elif args.organize_by == "link":
                        os.symlink(os.path.abspath(dup), target_path)
        
        print(f"\næ€»è®¡: å¤„ç†äº† {sum(len(g)-1 for g in duplicates)} ä¸ªé‡å¤æ–‡ä»¶")
        print(f"å¯èŠ‚çœç©ºé—´: {format_size(total_saved)}")
        return
    
    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
    file_count = 0
    moved_count = 0
    skipped_count = 0
    
    for file_path in all_files:
        rel_path = os.path.relpath(file_path, source_dir)
        
        # å¦‚æœæ˜¯é€’å½’æ¨¡å¼ä¸”ä¿æŒç»“æ„ï¼Œéœ€è¦è°ƒæ•´ç›®æ ‡ç›®å½•
        if args.recursive and args.keep_structure:
            file_dir = os.path.dirname(rel_path)
            sub_source_dir = os.path.join(source_dir, file_dir) if file_dir else source_dir
        else:
            sub_source_dir = source_dir
        
        # å¤„ç†æ–‡ä»¶
        target_path = process_file(file_path, sub_source_dir, args, custom_rules)
        
        if not target_path:
            skipped_count += 1
            continue
        
        file_count += 1
        
        if file_path == target_path:
            continue
        
        print(f"{'[é¢„è§ˆ]' if args.dry_run else ''} {rel_path} -> {os.path.relpath(target_path, source_dir)}")
        
        # æ‰§è¡Œæ“ä½œï¼ˆé™¤éæ˜¯é¢„è§ˆæ¨¡å¼ï¼‰
        if not args.dry_run:
            try:
                if args.organize_by == "move":
                    shutil.move(file_path, target_path)
                elif args.organize_by == "copy":
                    shutil.copy2(file_path, target_path)
                elif args.organize_by == "link":
                    os.symlink(os.path.abspath(file_path), target_path)
                
                moved_count += 1
            except Exception as e:
                print(f"é”™è¯¯: æ— æ³•å¤„ç†æ–‡ä»¶ '{rel_path}': {e}")
                skipped_count += 1
    
    print("\n" + "=" * 60)
    if args.dry_run:
        print(f"é¢„è§ˆå®Œæˆ: å°†å¤„ç† {file_count} ä¸ªæ–‡ä»¶ (è·³è¿‡ {skipped_count} ä¸ª)")
    else:
        print(f"æ•´ç†å®Œæˆ: å·²å¤„ç† {moved_count} ä¸ªæ–‡ä»¶ (è·³è¿‡ {skipped_count} ä¸ª)")

if __name__ == "__main__":
    args = parse_arguments()
    organize_files(args)
